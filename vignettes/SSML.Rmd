---
title: "SSML"
author:
- name: Lucas Schiffer
  affiliation:
  - &1 Bioinformatics Graduate Program, Boston University, Boston, MA
- name: Rebecca Panitch
  affiliation:
  - *1
date: '`r format(Sys.Date(), "%B %e, %Y")`'
abstract: >
    SSML aims to impliment semi-supervised machine learning methods for
    Bioconductor SummarizedExperiment class objects to predict labels of
    carcinogenicity. However, we will write our methods to be sufficiently
    general so as to apply to additional problems.
package: SSML
output:
    BiocStyle::html_document
vignette: >
    %\VignetteIndexEntry{SSML}
    %\VignetteEncoding{UTF-8}
    %\VignetteEngine{knitr::rmarkdown}
editor_options:
    chunk_output_type: console
---

# Prerequisites

The following `r BiocStyle::CRANpkg("knitr")` options will be used in this
vignette to provide the most useful and concise output.

```{r}
knitr::opts_chunk$set(cache = FALSE)
knitr::opts_chunk$set(message = FALSE)
```

The following packages will be used in this vignette to provide demonstrative
examples of what a user might do with
`r BiocStyle::Githubpkg("schifferl/SSML")`.

```{r}
library(caret)
library(SSML)
library(SSL)
```

Pipe operators from the `r BiocStyle::CRANpkg("magrittr")` package are used in
this vignette to provide the most elegant and concise syntax. See the
`r BiocStyle::CRANpkg("magrittr")` vignette if the syntax is unclear.

# Introduction

The `r BiocStyle::Githubpkg("schifferl/SSML")` package contains a single toy
data set, `TCGA`, created from the `r BiocStyle::Biocpkg("curatedTCGAData")`
package. It is provided as a Bioconductor `SummarizedExperiment` object (see the
`r BiocStyle::Biocpkg("SummarizedExperiment")` vignette for further details) as
shown below.

```{r}
TCGA
```

The toy data set is necessary as it represents the input format we are designing
our methods around, the Bioconductor `SummarizedExperiment` object. In the
future, further data sets from the
[Carcinogenome Project](https://carcinogenome.org/),
[DrugMatrix/ToxFX](https://ntp.niehs.nih.gov/results/toxfx/index.html), and
[TG-GATEs](https://toxico.nibiohn.go.jp/english/) will be added. These later
additions will be used to evaluate method performance and thus we will not need
them immediately â€“ not to mention the work necessary to coerce them to
`SummarizedExperiment` objects.

# Framework

We hope to address cross-validation problems in biology generally and take the
view that a framework is the best way to do so. Given a `SummarizedExperiment`
object, we will predict label through a series of procedural steps by first
provisioning training/test sets in a standard way. Then by wrapping existing
machine learning methods to accept the output of the provisioning step. Finally,
we will evaluate method performance through the use of ROC curves and AUC
calculations. All output from machine learning methods we wrap will be
standardized such that evaluation can be implimented as a general purpose
method.

# Provisioning

## Input Object Coercion

A series of helper functions are necessary to extract the components of a
`SummarizedExperiment` object and merge them into a `data.frame` object. The
coercion is a prerequisite for most existing machine learning methods because
the more traditional "wide" format is expected as input and
`SummarizedExperiment` objects are a vastly different representation as compared
`data.frame` objects (again, the expected input format). The three functions
shown below are used for this purpose.

```{r}
extract_colData <- function(x) {
    SummarizedExperiment::colData(x) %>%
        S4Vectors::as.data.frame() %>%
        tibble::rownames_to_column()    
}
```

```{r}
extract_assay <- function(x) {
    SummarizedExperiment::assay(x) %>%
        base::t() %>%
        S4Vectors::as.data.frame() %>%
        tibble::rownames_to_column()   
}
```

```{r}
prepare_data <- function(x) {
    base::list(extract_colData, extract_assay) %>%
        purrr::invoke_map(x = x) %>%
        purrr::reduce(base::merge.data.frame)
}
```

## Training/Test Set Splitting

The following method represents our current work on training/test set splitting.

```{r}
provision_sets <- function(x, together = NULL, ...) {
    prepare_data(x)
}
```

# Wrapping

## Random Forest

The following method represents our current work on wrapping random forest.

```{r}
random_forest <- function(x, ...) {
    
}
```

## Support Vector Machine

The following method represents our current work on wrapping random forest.

```{r}
support_vector_machine <- function(x, ...) {
    
}
```

## Gradient Boosting

The following method represents our current work on wrapping gradient boosting.

```{r}
gradient_boosting <- function(x, ...) {
    
}
```


# Evaluation

The following method represents our current work on evaluation.

```{r}
evaluate_performance <- function(x, ...) {
    
}
```

# Examples

## Random Forests

```{r}
provision_sets(TCGA) %>%
    random_forest() %>%
    evaluate_performance()
```

## Support Vector Machine

```{r}
provision_sets(TCGA) %>%
    support_vector_machine() %>%
    evaluate_performance()
```

## Gradient Boosting

```{r}
provision_sets(TCGA) %>%
    gradient_boosting() %>%
    evaluate_performance()
```

# Session Info

```{r}
sessionInfo()
```
